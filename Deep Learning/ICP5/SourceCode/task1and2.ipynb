{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #Basic packages for creating dataframes and loading dataset\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt #Package for visualization\n",
    "\n",
    "import re #importing package for Regular expression operations\n",
    "\n",
    "from sklearn.model_selection import train_test_split #Package for splitting the data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #Package for conversion of categorical to Numerical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer #Tokenization\n",
    "from keras.preprocessing.sequence import pad_sequences #Add zeros or crop based on the length\n",
    "from keras.models import Sequential #Sequential Neural Network\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D #For layers in Neural Network\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentiment.csv') #Looading the dataset\n",
    "\n",
    "data = data[['text','sentiment']] # Keeping only the neccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower()) #converting to lower case\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))) #only a-z,A-Z,0-9 would be remaining in the data, else special characters are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ') #Removing Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(X)\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
    "y = to_categorical(integer_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lavanya/opt/anaconda3/envs/env_full/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      " - 24s - loss: 0.8318 - accuracy: 0.6418\n",
      "0.7780609636808806\n",
      "0.6743119359016418\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model = createmodel() #Function call to Sequential Neural Network\n",
    "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) #verbose the higher, the more messages\n",
    "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
    "print(score)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model and use the saved model to predict on new text data (ex, “A lot of good things are happening. We are respected again throughout the world, and that's a great thing.@realDonaldTrump”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentimentAnalysis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model= load_model('sentimentAnalysis.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ... 2 0 2]\n",
      "0         Neutral\n",
      "1        Positive\n",
      "2         Neutral\n",
      "3        Positive\n",
      "4        Positive\n",
      "           ...   \n",
      "13866    Negative\n",
      "13867    Positive\n",
      "13868    Positive\n",
      "13869    Negative\n",
      "13870    Positive\n",
      "Name: sentiment, Length: 13871, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(integer_encoded)\n",
    "print(data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
    "sentence = tokenizer.texts_to_sequences(sentence)\n",
    "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0)\n",
    "sentiment = model.predict_classes(sentence,batch_size=1,verbose = 2)[0]\n",
    "print(sentiment)\n",
    "if sentiment == 0:\n",
    "  print(\"Neutral\")\n",
    "elif sentiment < 0:\n",
    "  print(\"Negative\")\n",
    "elif sentiment > 0:\n",
    "  print(\"Positive\")\n",
    "else:\n",
    "  print(\"Can not be determined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV on the source code provided in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 42s - loss: 0.8346 - accuracy: 0.6404\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.8259 - accuracy: 0.6477\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.8278 - accuracy: 0.6466\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.8312 - accuracy: 0.6467\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.8254 - accuracy: 0.6403\n",
      "Epoch 1/2\n",
      " - 44s - loss: 0.8341 - accuracy: 0.6472\n",
      "Epoch 2/2\n",
      " - 41s - loss: 0.6907 - accuracy: 0.7084\n",
      "Epoch 1/2\n",
      " - 46s - loss: 0.8320 - accuracy: 0.6462\n",
      "Epoch 2/2\n",
      " - 45s - loss: 0.6910 - accuracy: 0.7117\n",
      "Epoch 1/2\n",
      " - 45s - loss: 0.8267 - accuracy: 0.6423\n",
      "Epoch 2/2\n",
      " - 44s - loss: 0.6844 - accuracy: 0.7117\n",
      "Epoch 1/2\n",
      " - 43s - loss: 0.8357 - accuracy: 0.6421\n",
      "Epoch 2/2\n",
      " - 42s - loss: 0.6894 - accuracy: 0.7067\n",
      "Epoch 1/2\n",
      " - 48s - loss: 0.8255 - accuracy: 0.6468\n",
      "Epoch 2/2\n",
      " - 48s - loss: 0.6764 - accuracy: 0.7158\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.8379 - accuracy: 0.6427\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.8304 - accuracy: 0.6450\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.8338 - accuracy: 0.6403\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.8346 - accuracy: 0.6389\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.8347 - accuracy: 0.6391\n",
      "Epoch 1/2\n",
      " - 30s - loss: 0.8299 - accuracy: 0.6445\n",
      "Epoch 2/2\n",
      " - 28s - loss: 0.6908 - accuracy: 0.7084\n",
      "Epoch 1/2\n",
      " - 29s - loss: 0.8321 - accuracy: 0.6455\n",
      "Epoch 2/2\n",
      " - 30s - loss: 0.6965 - accuracy: 0.7090\n",
      "Epoch 1/2\n",
      " - 32s - loss: 0.8367 - accuracy: 0.6379\n",
      "Epoch 2/2\n",
      " - 28s - loss: 0.6850 - accuracy: 0.7092\n",
      "Epoch 1/2\n",
      " - 30s - loss: 0.8366 - accuracy: 0.6429\n",
      "Epoch 2/2\n",
      " - 30s - loss: 0.6859 - accuracy: 0.7115\n",
      "Epoch 1/2\n",
      " - 30s - loss: 0.8275 - accuracy: 0.6401\n",
      "Epoch 2/2\n",
      " - 28s - loss: 0.6786 - accuracy: 0.7126\n",
      "Epoch 1/1\n",
      " - 20s - loss: 0.8447 - accuracy: 0.6372\n",
      "Epoch 1/1\n",
      " - 22s - loss: 0.8391 - accuracy: 0.6399\n",
      "Epoch 1/1\n",
      " - 20s - loss: 0.8536 - accuracy: 0.6338\n",
      "Epoch 1/1\n",
      " - 21s - loss: 0.8517 - accuracy: 0.6289\n",
      "Epoch 1/1\n",
      " - 20s - loss: 0.8417 - accuracy: 0.6354\n",
      "Epoch 1/2\n",
      " - 21s - loss: 0.8439 - accuracy: 0.6381\n",
      "Epoch 2/2\n",
      " - 18s - loss: 0.7045 - accuracy: 0.7018\n",
      "Epoch 1/2\n",
      " - 26s - loss: 0.8473 - accuracy: 0.6347\n",
      "Epoch 2/2\n",
      " - 19s - loss: 0.7016 - accuracy: 0.7018\n",
      "Epoch 1/2\n",
      " - 21s - loss: 0.8533 - accuracy: 0.6337\n",
      "Epoch 2/2\n",
      " - 18s - loss: 0.7100 - accuracy: 0.6987\n",
      "Epoch 1/2\n",
      " - 20s - loss: 0.8495 - accuracy: 0.6332\n",
      "Epoch 2/2\n",
      " - 19s - loss: 0.6909 - accuracy: 0.7112\n",
      "Epoch 1/2\n",
      " - 21s - loss: 0.8446 - accuracy: 0.6385\n",
      "Epoch 2/2\n",
      " - 21s - loss: 0.6859 - accuracy: 0.7069\n",
      "Epoch 1/2\n",
      " - 64s - loss: 0.8202 - accuracy: 0.6497\n",
      "Epoch 2/2\n",
      " - 59s - loss: 0.6840 - accuracy: 0.7094\n",
      "Best: 0.674699 using {'batch_size': 10, 'epochs': 2}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=createmodel,verbose=2)\n",
    "batch_size= [10, 20, 40]\n",
    "epochs = [1, 2]\n",
    "param_grid= {'batch_size':batch_size, 'epochs':epochs}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result= grid.fit(X_train,Y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
